import pandas as pd
import sys, getopt, os, tarfile, fnmatch, csv

# Relative or Absolute path to the directory which contains the reports generated by the Cost Management Metrics Operator
inputDirName = sys.argv[1]

# Read the contents of the provided directory
entries = os.listdir(inputDirName)
#print('Provided Directory Name: '+inputDirName)

finalDataFrame = pd.DataFrame()

# List to store the final data to write to CSV file
finalCSVData = []

""""
# Step 1 - Logic to extract all the reports generated for a particular month
# Iterate through the list of directories
for entry in entries:
    # Store the absolute path of the file
    fileName = inputDirName +'/'+ entry

    # Check if it is a file and NOT a directory
    isFile = os.path.isfile(fileName)
    if isFile:
        # Check if it is a TAR file
        if tarfile.is_tarfile(fileName):
            print(fileName)

            #isDirExist = os.path.exists(fileName)
            #if not isDirExist:
            #    os.makedirs(fileName)

            #Extract the contents of the TAR file
            file = tarfile.open(fileName)
            file.extractall(fileName[:-7])
            file.close()
"""

# Step 2 - Logic to look at the reports generated every 6 hours
# Iterate through the list of directories
for entry in entries:
    # Store the absolute path of the file
    dirName = inputDirName + entry
    # Check if it is a file and NOT a directory
    isDir = os.path.isdir(dirName)
    if isDir:
        #print('Directory Name : ' + dirName)
        
        # Read the contents of the provided directory
        fileList = os.listdir(dirName)
        pattern = '*_openshift_usage_report.*.csv'

        for file in fileList:
            if fnmatch.fnmatch(file, pattern):
                fileName = dirName + '/' + file
                csvData = pd.read_csv(fileName)
                #print('Usage File : ' + fileName)

                columnsList = list(csvData.columns)
                
                if('node_capacity_cpu_cores' in columnsList):
                    #print('File '+fileName+' has the column "node_capacity_cpu_cores"')

                    subsetData = csvData[['interval_start', 'interval_end', 'node', 'node_capacity_cpu_cores']]
                    vCpuUsed = subsetData.groupby(['interval_start', 'interval_end', 'node'])['node_capacity_cpu_cores'].max()
                    finalCSVData.append(vCpuUsed)

#print(finalCSVData)

#finalDataFrame = pd.concat(finalCSVData)
#finalDataFrame.sort_values('interval_start')
#print(finalDataFrame)
#finalData.to_csv('vcpu_count.csv')

"""
with open('vcpu_count.csv', 'w', encoding='UTF8') as f:
    writer = csv.writer(f, delimiter="\n")

    # write the header
    #writer.writerow(header)

    # write the data
    writer.writerow(finalCSVData)
"""